file_path,api_count,code
layers.py,10,"b'import torch\nimport torch.nn as nn\n\n# Adapted from https://github.com/gpeyre/SinkhornAutoDiff\nclass SinkhornDistance(nn.Module):\n    r""""""\n    Given two empirical measures each with :math:`P_1` locations\n    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n    outputs an approximation of the regularized OT cost for point clouds.\n\n    Args:\n        eps (float): regularization coefficient\n        max_iter (int): maximum number of Sinkhorn iterations\n        reduction (string, optional): Specifies the reduction to apply to the output:\n            \'none\' | \'mean\' | \'sum\'. \'none\': no reduction will be applied,\n            \'mean\': the sum of the output will be divided by the number of\n            elements in the output, \'sum\': the output will be summed. Default: \'none\'\n\n    Shape:\n        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n    """"""\n    def __init__(self, eps, max_iter, reduction=\'none\'):\n        super(SinkhornDistance, self).__init__()\n        self.eps = eps\n        self.max_iter = max_iter\n        self.reduction = reduction\n\n    def forward(self, x, y):\n        # The Sinkhorn algorithm takes as input three variables :\n        C = self._cost_matrix(x, y)  # Wasserstein cost function\n        x_points = x.shape[-2]\n        y_points = y.shape[-2]\n        if x.dim() == 2:\n            batch_size = 1\n        else:\n            batch_size = x.shape[0]\n\n        # both marginals are fixed with equal weights\n        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n                         requires_grad=False).fill_(1.0 / x_points).squeeze()\n        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n                         requires_grad=False).fill_(1.0 / y_points).squeeze()\n\n        u = torch.zeros_like(mu)\n        v = torch.zeros_like(nu)\n        # To check if algorithm terminates because of threshold\n        # or max iterations reached\n        actual_nits = 0\n        # Stopping criterion\n        thresh = 1e-1\n\n        # Sinkhorn iterations\n        for i in range(self.max_iter):\n            u1 = u  # useful to check the update\n            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n            err = (u - u1).abs().sum(-1).mean()\n\n            actual_nits += 1\n            if err.item() < thresh:\n                break\n\n        U, V = u, v\n        # Transport plan pi = diag(a)*K*diag(b)\n        pi = torch.exp(self.M(C, U, V))\n        # Sinkhorn distance\n        cost = torch.sum(pi * C, dim=(-2, -1))\n\n        if self.reduction == \'mean\':\n            cost = cost.mean()\n        elif self.reduction == \'sum\':\n            cost = cost.sum()\n\n        return cost, pi, C\n\n    def M(self, C, u, v):\n        ""Modified cost for logarithmic updates""\n        ""$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$""\n        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n\n    @staticmethod\n    def _cost_matrix(x, y, p=2):\n        ""Returns the matrix of $|x_i-y_j|^p$.""\n        x_col = x.unsqueeze(-2)\n        y_lin = y.unsqueeze(-3)\n        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n        return C\n\n    @staticmethod\n    def ave(u, u1, tau):\n        ""Barycenter subroutine, used by kinetic acceleration through extrapolation.""\n        return tau * u + (1 - tau) * u1\n'"
