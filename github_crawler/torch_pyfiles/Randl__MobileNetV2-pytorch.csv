file_path,api_count,code
clr.py,4,"b'# temporary file until https://github.com/pytorch/pytorch/pull/2016 is merged (hopefully 0.5)\n\n\nimport numpy as np\nfrom torch.optim import Optimizer\n\n\nclass CyclicLR(object):\n    """"""Sets the learning rate of each parameter group according to\n    cyclical learning rate policy (CLR). The policy cycles the learning\n    rate between two boundaries with a constant frequency, as detailed in\n    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n    The distance between the two boundaries can be scaled on a per-iteration\n    or per-cycle basis.\n    Cyclical learning rate policy changes the learning rate after every batch.\n    `batch_step` should be called after a batch has been used for training.\n    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n    This class has three built-in policies, as put forth in the paper:\n    ""triangular"":\n        A basic triangular cycle w/ no amplitude scaling.\n    ""triangular2"":\n        A basic triangular cycle that scales initial amplitude by half each cycle.\n    ""exp_range"":\n        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n        cycle iteration.\n    This implementation was adapted from the github repo: `bckenstler/CLR`_\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        base_lr (float or list): Initial learning rate which is the\n            lower boundary in the cycle for eachparam groups.\n            Default: 0.001\n        max_lr (float or list): Upper boundaries in the cycle for\n            each parameter group. Functionally,\n            it defines the cycle amplitude (max_lr - base_lr).\n            The lr at any cycle is the sum of base_lr\n            and some scaling of the amplitude; therefore\n            max_lr may not actually be reached depending on\n            scaling function. Default: 0.006\n        step_size (int): Number of training iterations per\n            half cycle. Authors suggest setting step_size\n            2-8 x training iterations in epoch. Default: 2000\n        mode (str): One of {triangular, triangular2, exp_range}.\n            Values correspond to policies detailed above.\n            If scale_fn is not None, this argument is ignored.\n            Default: \'triangular\'\n        gamma (float): Constant in \'exp_range\' scaling function:\n            gamma**(cycle iterations)\n            Default: 1.0\n        scale_fn (function): Custom scaling policy defined by a single\n            argument lambda function, where\n            0 <= scale_fn(x) <= 1 for all x >= 0.\n            mode paramater is ignored\n            Default: None\n        scale_mode (str): {\'cycle\', \'iterations\'}.\n            Defines whether scale_fn is evaluated on\n            cycle number or cycle iterations (training\n            iterations since start of cycle).\n            Default: \'cycle\'\n        last_batch_iteration (int): The index of the last batch. Default: -1\n    Example:\n        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n        >>> scheduler = torch.optim.CyclicLR(optimizer)\n        >>> data_loader = torch.utils.data.DataLoader(...)\n        >>> for epoch in range(10):\n        >>>     for batch in data_loader:\n        >>>         scheduler.batch_step()\n        >>>         train_batch(...)\n    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n    """"""\n\n    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n                 step_size=2000, mode=\'triangular\', gamma=1.,\n                 scale_fn=None, scale_mode=\'cycle\', last_batch_iteration=-1):\n\n        if not isinstance(optimizer, Optimizer):\n            raise TypeError(\'{} is not an Optimizer\'.format(\n                type(optimizer).__name__))\n        self.optimizer = optimizer\n\n        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n            if len(base_lr) != len(optimizer.param_groups):\n                raise ValueError(""expected {} base_lr, got {}"".format(\n                    len(optimizer.param_groups), len(base_lr)))\n            self.base_lrs = list(base_lr)\n        else:\n            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n\n        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n            if len(max_lr) != len(optimizer.param_groups):\n                raise ValueError(""expected {} max_lr, got {}"".format(\n                    len(optimizer.param_groups), len(max_lr)))\n            self.max_lrs = list(max_lr)\n        else:\n            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n\n        self.step_size = step_size\n\n        if mode not in [\'triangular\', \'triangular2\', \'exp_range\'] \\\n                and scale_fn is None:\n            raise ValueError(\'mode is invalid and scale_fn is None\')\n\n        self.mode = mode\n        self.gamma = gamma\n\n        if scale_fn is None:\n            if self.mode == \'triangular\':\n                self.scale_fn = self._triangular_scale_fn\n                self.scale_mode = \'cycle\'\n            elif self.mode == \'triangular2\':\n                self.scale_fn = self._triangular2_scale_fn\n                self.scale_mode = \'cycle\'\n            elif self.mode == \'exp_range\':\n                self.scale_fn = self._exp_range_scale_fn\n                self.scale_mode = \'iterations\'\n        else:\n            self.scale_fn = scale_fn\n            self.scale_mode = scale_mode\n\n        self.batch_step(last_batch_iteration + 1)\n        self.last_batch_iteration = last_batch_iteration\n\n    def batch_step(self, batch_iteration=None):\n        if batch_iteration is None:\n            batch_iteration = self.last_batch_iteration + 1\n        self.last_batch_iteration = batch_iteration\n        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n            param_group[\'lr\'] = lr\n\n    def _triangular_scale_fn(self, x):\n        return 1.\n\n    def _triangular2_scale_fn(self, x):\n        return 1 / (2. ** (x - 1))\n\n    def _exp_range_scale_fn(self, x):\n        return self.gamma ** (x)\n\n    def get_lr(self):\n        step_size = float(self.step_size)\n        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n\n        lrs = []\n        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n        for param_group, base_lr, max_lr in param_lrs:\n            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n            if self.scale_mode == \'cycle\':\n                lr = base_lr + base_height * self.scale_fn(cycle)\n            else:\n                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n            lrs.append(lr)\n        return lrs\n'"
data.py,5,"b""import os\n\nimport torch\nimport torch.nn.parallel\nimport torch.optim\nimport torch.utils.data\nfrom torchvision import datasets, transforms\n\n__imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n                    'std': [0.229, 0.224, 0.225]}\n\n\ndef inception_preproccess(input_size, normalize=__imagenet_stats):\n    return transforms.Compose([\n        transforms.RandomResizedCrop(input_size),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(**normalize)\n    ])\n\n\ndef scale_crop(input_size, scale_size=None, normalize=__imagenet_stats):\n    t_list = [\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize(**normalize),\n    ]\n    if scale_size != input_size:\n        t_list = [transforms.Resize(scale_size)] + t_list\n\n    return transforms.Compose(t_list)\n\n\ndef get_transform(augment=True, input_size=224):\n    normalize = __imagenet_stats\n    scale_size = int(input_size / 0.875)\n    if augment:\n        return inception_preproccess(input_size=input_size, normalize=normalize)\n    else:\n        return scale_crop(input_size=input_size, scale_size=scale_size, normalize=normalize)\n\n\ndef get_loaders(dataroot, val_batch_size, train_batch_size, input_size, workers):\n    val_data = datasets.ImageFolder(root=os.path.join(dataroot, 'val'), transform=get_transform(False, input_size))\n    val_loader = torch.utils.data.DataLoader(val_data, batch_size=val_batch_size, shuffle=False, num_workers=workers,\n                                             pin_memory=True)\n\n    train_data = datasets.ImageFolder(root=os.path.join(dataroot, 'train'),\n                                      transform=get_transform(input_size=input_size))\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=train_batch_size, shuffle=True,\n                                               num_workers=workers, pin_memory=True)\n    return train_loader, val_loader\n"""
flops_benchmark.py,9,"b'#### https://github.com/warmspringwinds/pytorch-segmentation-detection/blob/master/pytorch_segmentation_detection/utils/flops_benchmark.py\nimport torch\n\n\n# ---- Public functions\n\ndef add_flops_counting_methods(net_main_module):\n    """"""Adds flops counting functions to an existing model. After that\n    the flops count should be activated and the model should be run on an input\n    image.\n\n    Example:\n\n    fcn = add_flops_counting_methods(fcn)\n    fcn = fcn.cuda().train()\n    fcn.start_flops_count()\n\n\n    _ = fcn(batch)\n\n    fcn.compute_average_flops_cost() / 1e9 / 2 # Result in GFLOPs per image in batch\n\n    Important: dividing by 2 only works for resnet models -- see below for the details\n    of flops computation.\n\n    Attention: we are counting multiply-add as two flops in this work, because in\n    most resnet models convolutions are bias-free (BN layers act as bias there)\n    and it makes sense to count muliply and add as separate flops therefore.\n    This is why in the above example we divide by 2 in order to be consistent with\n    most modern benchmarks. For example in ""Spatially Adaptive Computatin Time for Residual\n    Networks"" by Figurnov et al multiply-add was counted as two flops.\n\n    This module computes the average flops which is necessary for dynamic networks which\n    have different number of executed layers. For static networks it is enough to run the network\n    once and get statistics (above example).\n\n    Implementation:\n    The module works by adding batch_count to the main module which tracks the sum\n    of all batch sizes that were run through the network.\n\n    Also each convolutional layer of the network tracks the overall number of flops\n    performed.\n\n    The parameters are updated with the help of registered hook-functions which\n    are being called each time the respective layer is executed.\n\n    Parameters\n    ----------\n    net_main_module : torch.nn.Module\n        Main module containing network\n\n    Returns\n    -------\n    net_main_module : torch.nn.Module\n        Updated main module with new methods/attributes that are used\n        to compute flops.\n    """"""\n\n    # adding additional methods to the existing module object,\n    # this is done this way so that each function has access to self object\n    net_main_module.start_flops_count = start_flops_count.__get__(net_main_module)\n    net_main_module.stop_flops_count = stop_flops_count.__get__(net_main_module)\n    net_main_module.reset_flops_count = reset_flops_count.__get__(net_main_module)\n    net_main_module.compute_average_flops_cost = compute_average_flops_cost.__get__(net_main_module)\n\n    net_main_module.reset_flops_count()\n\n    # Adding varialbles necessary for masked flops computation\n    net_main_module.apply(add_flops_mask_variable_or_reset)\n\n    return net_main_module\n\n\ndef compute_average_flops_cost(self):\n    """"""\n    A method that will be available after add_flops_counting_methods() is called\n    on a desired net object.\n\n    Returns current mean flops consumption per image.\n\n    """"""\n\n    batches_count = self.__batch_counter__\n\n    flops_sum = 0\n\n    for module in self.modules():\n\n        if isinstance(module, torch.nn.Conv2d):\n            flops_sum += module.__flops__\n\n    return flops_sum / batches_count\n\n\ndef start_flops_count(self):\n    """"""\n    A method that will be available after add_flops_counting_methods() is called\n    on a desired net object.\n\n    Activates the computation of mean flops consumption per image.\n    Call it before you run the network.\n\n    """"""\n\n    add_batch_counter_hook_function(self)\n\n    self.apply(add_flops_counter_hook_function)\n\n\ndef stop_flops_count(self):\n    """"""\n    A method that will be available after add_flops_counting_methods() is called\n    on a desired net object.\n\n    Stops computing the mean flops consumption per image.\n    Call whenever you want to pause the computation.\n\n    """"""\n\n    remove_batch_counter_hook_function(self)\n\n    self.apply(remove_flops_counter_hook_function)\n\n\ndef reset_flops_count(self):\n    """"""\n    A method that will be available after add_flops_counting_methods() is called\n    on a desired net object.\n\n    Resets statistics computed so far.\n\n    """"""\n\n    add_batch_counter_variables_or_reset(self)\n\n    self.apply(add_flops_counter_variable_or_reset)\n\n\ndef add_flops_mask(module, mask):\n    def add_flops_mask_func(module):\n        if isinstance(module, torch.nn.Conv2d):\n            module.__mask__ = mask\n\n    module.apply(add_flops_mask_func)\n\n\ndef remove_flops_mask(module):\n    module.apply(add_flops_mask_variable_or_reset)\n\n\n# ---- Internal functions\n\n\ndef conv_flops_counter_hook(conv_module, input, output):\n    # Can have multiple inputs, getting the first one\n    input = input[0]\n\n    batch_size = input.shape[0]\n    output_height, output_width = output.shape[2:]\n\n    kernel_height, kernel_width = conv_module.kernel_size\n    in_channels = conv_module.in_channels\n    out_channels = conv_module.out_channels\n    groups = conv_module.groups\n\n    # We count multiply-add as 2 flops\n    conv_per_position_flops = 2 * kernel_height * kernel_width * in_channels * out_channels / groups\n\n    active_elements_count = batch_size * output_height * output_width\n\n    if conv_module.__mask__ is not None:\n        # (b, 1, h, w)\n        flops_mask = conv_module.__mask__.expand(batch_size, 1, output_height, output_width)\n        active_elements_count = flops_mask.sum()\n\n    overall_conv_flops = conv_per_position_flops * active_elements_count\n\n    bias_flops = 0\n\n    if conv_module.bias is not None:\n        bias_flops = out_channels * active_elements_count\n\n    overall_flops = overall_conv_flops + bias_flops\n\n    conv_module.__flops__ += overall_flops\n\n\ndef batch_counter_hook(module, input, output):\n    # Can have multiple inputs, getting the first one\n    input = input[0]\n\n    batch_size = input.shape[0]\n\n    module.__batch_counter__ += batch_size\n\n\ndef add_batch_counter_variables_or_reset(module):\n    module.__batch_counter__ = 0\n\n\ndef add_batch_counter_hook_function(module):\n    if hasattr(module, \'__batch_counter_handle__\'):\n        return\n\n    handle = module.register_forward_hook(batch_counter_hook)\n    module.__batch_counter_handle__ = handle\n\n\ndef remove_batch_counter_hook_function(module):\n    if hasattr(module, \'__batch_counter_handle__\'):\n        module.__batch_counter_handle__.remove()\n\n        del module.__batch_counter_handle__\n\n\ndef add_flops_counter_variable_or_reset(module):\n    if isinstance(module, torch.nn.Conv2d):\n        module.__flops__ = 0\n\n\ndef add_flops_counter_hook_function(module):\n    if isinstance(module, torch.nn.Conv2d):\n\n        if hasattr(module, \'__flops_handle__\'):\n            return\n\n        handle = module.register_forward_hook(conv_flops_counter_hook)\n        module.__flops_handle__ = handle\n\n\ndef remove_flops_counter_hook_function(module):\n    if isinstance(module, torch.nn.Conv2d):\n\n        if hasattr(module, \'__flops_handle__\'):\n            module.__flops_handle__.remove()\n\n            del module.__flops_handle__\n\n\n# --- Masked flops counting\n\n\n# Also being run in the initialization\ndef add_flops_mask_variable_or_reset(module):\n    if isinstance(module, torch.nn.Conv2d):\n        module.__mask__ = None\n\n\ndef count_flops(model, batch_size, device, dtype, input_size, in_channels, *params):\n    net = model(*params, input_size=input_size)\n    # print(net)\n    net = add_flops_counting_methods(net)\n\n    net.to(device=device, dtype=dtype)\n    net = net.train()\n\n    batch = torch.randn(batch_size, in_channels, input_size, input_size).to(device=device, dtype=dtype)\n    net.start_flops_count()\n\n    _ = net(batch)\n    return net.compute_average_flops_cost() / 2  # Result in FLOPs\n'"
imagenet.py,15,"b'import argparse\nimport csv\nimport os\nimport random\nimport sys\nfrom datetime import datetime\n\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn.parallel\nimport torch.optim\nimport torch.utils.data\nfrom torch.optim.lr_scheduler import MultiStepLR\nfrom tqdm import trange\n\nimport flops_benchmark\nfrom clr import CyclicLR\nfrom data import get_loaders\nfrom logger import CsvLogger\nfrom model import MobileNet2\nfrom run import train, test, save_checkpoint, find_bounds_clr\n\nparser = argparse.ArgumentParser(description=\'MobileNetv2 training with PyTorch\')\nparser.add_argument(\'--dataroot\', required=True, metavar=\'PATH\',\n                    help=\'Path to ImageNet train and val folders, preprocessed as described in \'\n                         \'https://github.com/facebook/fb.resnet.torch/blob/master/INSTALL.md#download-the-imagenet-dataset\')\nparser.add_argument(\'--gpus\', default=None, help=\'List of GPUs used for training - e.g 0,1,3\')\nparser.add_argument(\'-j\', \'--workers\', default=4, type=int, metavar=\'N\',\n                    help=\'Number of data loading workers (default: 4)\')\nparser.add_argument(\'--type\', default=\'float32\', help=\'Type of tensor: float32, float16, float64. Default: float32\')\n\n# Optimization options\nparser.add_argument(\'--epochs\', type=int, default=400, help=\'Number of epochs to train.\')\nparser.add_argument(\'-b\', \'--batch-size\', default=64, type=int, metavar=\'N\', help=\'mini-batch size (default: 64)\')\nparser.add_argument(\'--learning_rate\', \'-lr\', type=float, default=0.01, help=\'The learning rate.\')\nparser.add_argument(\'--momentum\', \'-m\', type=float, default=0.9, help=\'Momentum.\')\nparser.add_argument(\'--decay\', \'-d\', type=float, default=4e-5, help=\'Weight decay (L2 penalty).\')\nparser.add_argument(\'--gamma\', type=float, default=0.1, help=\'LR is multiplied by gamma at scheduled epochs.\')\nparser.add_argument(\'--schedule\', type=int, nargs=\'+\', default=[200, 300],\n                    help=\'Decrease learning rate at these epochs.\')\n\n# CLR\nparser.add_argument(\'--clr\', dest=\'clr\', action=\'store_true\', help=\'Use CLR\')\nparser.add_argument(\'--min-lr\', type=float, default=1e-5, help=\'Minimal LR for CLR.\')\nparser.add_argument(\'--max-lr\', type=float, default=1, help=\'Maximal LR for CLR.\')\nparser.add_argument(\'--epochs-per-step\', type=int, default=20,\n                    help=\'Number of epochs per step in CLR, recommended to be between 2 and 10.\')\nparser.add_argument(\'--mode\', default=\'triangular2\', help=\'CLR mode. One of {triangular, triangular2, exp_range}\')\nparser.add_argument(\'--find-clr\', dest=\'find_clr\', action=\'store_true\',\n                    help=\'Run search for optimal LR in range (min_lr, max_lr)\')\n\n# Checkpoints\nparser.add_argument(\'-e\', \'--evaluate\', dest=\'evaluate\', action=\'store_true\', help=\'Just evaluate model\')\nparser.add_argument(\'--save\', \'-s\', type=str, default=\'\', help=\'Folder to save checkpoints.\')\nparser.add_argument(\'--results_dir\', metavar=\'RESULTS_DIR\', default=\'./results\', help=\'Directory to store results\')\nparser.add_argument(\'--resume\', default=\'\', type=str, metavar=\'PATH\', help=\'path to latest checkpoint (default: none)\')\nparser.add_argument(\'--start-epoch\', default=0, type=int, metavar=\'N\', help=\'manual epoch number (useful on restarts)\')\nparser.add_argument(\'--log-interval\', type=int, default=100, metavar=\'N\', help=\'Number of batches between log messages\')\nparser.add_argument(\'--seed\', type=int, default=None, metavar=\'S\', help=\'random seed (default: 1)\')\n\n# Architecture\nparser.add_argument(\'--scaling\', type=float, default=1, metavar=\'SC\', help=\'Scaling of MobileNet (default x1).\')\nparser.add_argument(\'--input-size\', type=int, default=224, metavar=\'I\',\n                    help=\'Input size of MobileNet, multiple of 32 (default 224).\')\n\n# https://github.com/keras-team/keras/blob/fe066966b5afa96f2f6b9f71ec0c71158b44068d/keras/applications/mobilenetv2.py#L30\nclaimed_acc_top1 = {224: {1.4: 0.75, 1.3: 0.744, 1.0: 0.718, 0.75: 0.698, 0.5: 0.654, 0.35: 0.603},\n                    192: {1.0: 0.707, 0.75: 0.687, 0.5: 0.639, 0.35: 0.582},\n                    160: {1.0: 0.688, 0.75: 0.664, 0.5: 0.610, 0.35: 0.557},\n                    128: {1.0: 0.653, 0.75: 0.632, 0.5: 0.577, 0.35: 0.508},\n                    96: {1.0: 0.603, 0.75: 0.588, 0.5: 0.512, 0.35: 0.455},\n                    }\nclaimed_acc_top5 = {224: {1.4: 0.925, 1.3: 0.921, 1.0: 0.910, 0.75: 0.896, 0.5: 0.864, 0.35: 0.829},\n                    192: {1.0: 0.901, 0.75: 0.889, 0.5: 0.854, 0.35: 0.812},\n                    160: {1.0: 0.890, 0.75: 0.873, 0.5: 0.832, 0.35: 0.791},\n                    128: {1.0: 0.869, 0.75: 0.855, 0.5: 0.808, 0.35: 0.750},\n                    96: {1.0: 0.832, 0.75: 0.816, 0.5: 0.758, 0.35: 0.704},\n                    }\n\n\ndef main():\n    args = parser.parse_args()\n\n    if args.seed is None:\n        args.seed = random.randint(1, 10000)\n    print(""Random Seed: "", args.seed)\n    random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    if args.gpus:\n        torch.cuda.manual_seed_all(args.seed)\n\n    time_stamp = datetime.now().strftime(\'%Y-%m-%d_%H-%M-%S\')\n    if args.evaluate:\n        args.results_dir = \'/tmp\'\n    if args.save is \'\':\n        args.save = time_stamp\n    save_path = os.path.join(args.results_dir, args.save)\n    if not os.path.exists(save_path):\n        os.makedirs(save_path)\n\n    if args.gpus is not None:\n        args.gpus = [int(i) for i in args.gpus.split(\',\')]\n        device = \'cuda:\' + str(args.gpus[0])\n        cudnn.benchmark = True\n    else:\n        device = \'cpu\'\n\n    if args.type == \'float64\':\n        dtype = torch.float64\n    elif args.type == \'float32\':\n        dtype = torch.float32\n    elif args.type == \'float16\':\n        dtype = torch.float16\n    else:\n        raise ValueError(\'Wrong type!\')  # TODO int8\n\n    model = MobileNet2(input_size=args.input_size, scale=args.scaling)\n    num_parameters = sum([l.nelement() for l in model.parameters()])\n    print(model)\n    print(\'number of parameters: {}\'.format(num_parameters))\n    print(\'FLOPs: {}\'.format(\n        flops_benchmark.count_flops(MobileNet2,\n                                    args.batch_size // len(args.gpus) if args.gpus is not None else args.batch_size,\n                                    device, dtype, args.input_size, 3, args.scaling)))\n\n    train_loader, val_loader = get_loaders(args.dataroot, args.batch_size, args.batch_size, args.input_size,\n                                           args.workers)\n    # define loss function (criterion) and optimizer\n    criterion = torch.nn.CrossEntropyLoss()\n    if args.gpus is not None:\n        model = torch.nn.DataParallel(model, args.gpus)\n    model.to(device=device, dtype=dtype)\n    criterion.to(device=device, dtype=dtype)\n\n    optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=args.momentum, weight_decay=args.decay,\n                                nesterov=True)\n    if args.find_clr:\n        find_bounds_clr(model, train_loader, optimizer, criterion, device, dtype, min_lr=args.min_lr,\n                        max_lr=args.max_lr, step_size=args.epochs_per_step * len(train_loader), mode=args.mode,\n                        save_path=save_path)\n        return\n\n    if args.clr:\n        scheduler = CyclicLR(optimizer, base_lr=args.min_lr, max_lr=args.max_lr,\n                             step_size=args.epochs_per_step * len(train_loader), mode=args.mode)\n    else:\n        scheduler = MultiStepLR(optimizer, milestones=args.schedule, gamma=args.gamma)\n\n    best_test = 0\n\n    # optionally resume from a checkpoint\n    data = None\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(""=> loading checkpoint \'{}\'"".format(args.resume))\n            checkpoint = torch.load(args.resume, map_location=device)\n            args.start_epoch = checkpoint[\'epoch\'] - 1\n            best_test = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})""\n                  .format(args.resume, checkpoint[\'epoch\']))\n        elif os.path.isdir(args.resume):\n            checkpoint_path = os.path.join(args.resume, \'checkpoint.pth.tar\')\n            csv_path = os.path.join(args.resume, \'results.csv\')\n            print(""=> loading checkpoint \'{}\'"".format(checkpoint_path))\n            checkpoint = torch.load(checkpoint_path, map_location=device)\n            args.start_epoch = checkpoint[\'epoch\'] - 1\n            best_test = checkpoint[\'best_prec1\']\n            model.load_state_dict(checkpoint[\'state_dict\'])\n            optimizer.load_state_dict(checkpoint[\'optimizer\'])\n            print(""=> loaded checkpoint \'{}\' (epoch {})"".format(checkpoint_path, checkpoint[\'epoch\']))\n            data = []\n            with open(csv_path) as csvfile:\n                reader = csv.DictReader(csvfile)\n                for row in reader:\n                    data.append(row)\n        else:\n            print(""=> no checkpoint found at \'{}\'"".format(args.resume))\n\n    if args.evaluate:\n        loss, top1, top5 = test(model, val_loader, criterion, device, dtype)  # TODO\n        return\n\n    csv_logger = CsvLogger(filepath=save_path, data=data)\n    csv_logger.save_params(sys.argv, args)\n\n    claimed_acc1 = None\n    claimed_acc5 = None\n    if args.input_size in claimed_acc_top1:\n        if args.scaling in claimed_acc_top1[args.input_size]:\n            claimed_acc1 = claimed_acc_top1[args.input_size][args.scaling]\n            claimed_acc5 = claimed_acc_top5[args.input_size][args.scaling]\n            csv_logger.write_text(\n                \'Claimed accuracies are: {:.2f}% top-1, {:.2f}% top-5\'.format(claimed_acc1 * 100., claimed_acc5 * 100.))\n    train_network(args.start_epoch, args.epochs, scheduler, model, train_loader, val_loader, optimizer, criterion,\n                  device, dtype, args.batch_size, args.log_interval, csv_logger, save_path, claimed_acc1, claimed_acc5,\n                  best_test)\n\n\ndef train_network(start_epoch, epochs, scheduler, model, train_loader, val_loader, optimizer, criterion, device, dtype,\n                  batch_size, log_interval, csv_logger, save_path, claimed_acc1, claimed_acc5, best_test):\n    for epoch in trange(start_epoch, epochs + 1):\n        if not isinstance(scheduler, CyclicLR):\n            scheduler.step()\n        train_loss, train_accuracy1, train_accuracy5, = train(model, train_loader, epoch, optimizer, criterion, device,\n                                                              dtype, batch_size, log_interval, scheduler)\n        test_loss, test_accuracy1, test_accuracy5 = test(model, val_loader, criterion, device, dtype)\n        csv_logger.write({\'epoch\': epoch + 1, \'val_error1\': 1 - test_accuracy1, \'val_error5\': 1 - test_accuracy5,\n                          \'val_loss\': test_loss, \'train_error1\': 1 - train_accuracy1,\n                          \'train_error5\': 1 - train_accuracy5, \'train_loss\': train_loss})\n        save_checkpoint({\'epoch\': epoch + 1, \'state_dict\': model.state_dict(), \'best_prec1\': best_test,\n                         \'optimizer\': optimizer.state_dict()}, test_accuracy1 > best_test, filepath=save_path)\n\n        csv_logger.plot_progress(claimed_acc1=claimed_acc1, claimed_acc5=claimed_acc5)\n\n        if test_accuracy1 > best_test:\n            best_test = test_accuracy1\n\n    csv_logger.write_text(\'Best accuracy is {:.2f}% top-1\'.format(best_test * 100.))\n\n\nif __name__ == \'__main__\':\n    main()\n'"
logger.py,0,"b""import csv\nimport os.path\n\nimport matplotlib\n\nmatplotlib.use('Agg')\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nplt.switch_backend('agg')\n\n\nclass CsvLogger:\n    def __init__(self, filepath='./', filename='results.csv', data=None):\n        self.log_path = filepath\n        self.log_name = filename\n        self.csv_path = os.path.join(self.log_path, self.log_name)\n        self.fieldsnames = ['epoch', 'val_error1', 'val_error5', 'val_loss', 'train_error1', 'train_error5',\n                            'train_loss']\n\n        with open(self.csv_path, 'w') as f:\n            writer = csv.DictWriter(f, fieldnames=self.fieldsnames)\n            writer.writeheader()\n\n        self.data = {}\n        for field in self.fieldsnames:\n            self.data[field] = []\n        if data is not None:\n            for d in data:\n                d_num = {}\n                for key in d:\n                    d_num[key] = float(d[key]) if key != 'epoch' else int(d[key])\n                self.write(d_num)\n\n    def write(self, data):\n        for k in self.data:\n            self.data[k].append(data[k])\n        with open(self.csv_path, 'a') as f:\n            writer = csv.DictWriter(f, fieldnames=self.fieldsnames)\n            writer.writerow(data)\n\n    def save_params(self, args, params):\n        with open(os.path.join(self.log_path, 'params.txt'), 'w') as f:\n            f.write('{}\\n'.format(' '.join(args)))\n            f.write('{}\\n'.format(params))\n\n    def write_text(self, text, print_t=True):\n        with open(os.path.join(self.log_path, 'params.txt'), 'a') as f:\n            f.write('{}\\n'.format(text))\n        if print_t:\n            print(text)\n\n    def plot_progress_errk(self, claimed_acc=None, title='MobileNetv2', k=1):\n        tr_str = 'train_error{}'.format(k)\n        val_str = 'val_error{}'.format(k)\n        plt.figure(figsize=(9, 8), dpi=300)\n        plt.plot(self.data[tr_str], label='Training error')\n        plt.plot(self.data[val_str], label='Validation error')\n        if claimed_acc is not None:\n            plt.plot((0, len(self.data[tr_str])), (1 - claimed_acc, 1 - claimed_acc), 'k--',\n                     label='Claimed validation error ({:.2f}%)'.format(100. * (1 - claimed_acc)))\n        plt.plot((0, len(self.data[tr_str])),\n                 (np.min(self.data[val_str]), np.min(self.data[val_str])), 'r--',\n                 label='Best validation error ({:.2f}%)'.format(100. * np.min(self.data[val_str])))\n        plt.title('Top-{} error for {}'.format(k, title))\n        plt.xlabel('Epoch')\n        plt.ylabel('Error')\n        plt.legend()\n        plt.xlim(0, len(self.data[tr_str]) + 1)\n        plt.savefig(os.path.join(self.log_path, 'top{}.png'.format(k)))\n\n    def plot_progress_loss(self, title='MobileNetv2'):\n        plt.figure(figsize=(9, 8), dpi=300)\n        plt.plot(self.data['train_loss'], label='Training')\n        plt.plot(self.data['val_loss'], label='Validation')\n        plt.title(title)\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.xlim(0, len(self.data['train_loss']) + 1)\n        plt.savefig(os.path.join(self.log_path, 'loss.png'))\n\n    def plot_progress(self, claimed_acc1=None, claimed_acc5=None, title='MobileNetv2'):\n        self.plot_progress_errk(claimed_acc1, title, 1)\n        self.plot_progress_errk(claimed_acc5, title, 5)\n        self.plot_progress_loss(title)\n        plt.close('all')\n"""
model.py,6,"b'from collections import OrderedDict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import init\n\n\ndef _make_divisible(v, divisor, min_value=None):\n    """"""\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    """"""\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\nclass LinearBottleneck(nn.Module):\n    def __init__(self, inplanes, outplanes, stride=1, t=6, activation=nn.ReLU6):\n        super(LinearBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, inplanes * t, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(inplanes * t)\n        self.conv2 = nn.Conv2d(inplanes * t, inplanes * t, kernel_size=3, stride=stride, padding=1, bias=False,\n                               groups=inplanes * t)\n        self.bn2 = nn.BatchNorm2d(inplanes * t)\n        self.conv3 = nn.Conv2d(inplanes * t, outplanes, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(outplanes)\n        self.activation = activation(inplace=True)\n        self.stride = stride\n        self.t = t\n        self.inplanes = inplanes\n        self.outplanes = outplanes\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.activation(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.activation(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.stride == 1 and self.inplanes == self.outplanes:\n            out += residual\n\n        return out\n\n\nclass MobileNet2(nn.Module):\n    """"""MobileNet2 implementation.\n    """"""\n\n    def __init__(self, scale=1.0, input_size=224, t=6, in_channels=3, num_classes=1000, activation=nn.ReLU6):\n        """"""\n        MobileNet2 constructor.\n        :param in_channels: (int, optional): number of channels in the input tensor.\n                Default is 3 for RGB image inputs.\n        :param input_size:\n        :param num_classes: number of classes to predict. Default\n                is 1000 for ImageNet.\n        :param scale:\n        :param t:\n        :param activation:\n        """"""\n\n        super(MobileNet2, self).__init__()\n\n        self.scale = scale\n        self.t = t\n        self.activation_type = activation\n        self.activation = activation(inplace=True)\n        self.num_classes = num_classes\n\n        self.num_of_channels = [32, 16, 24, 32, 64, 96, 160, 320]\n        # assert (input_size % 32 == 0)\n\n        self.c = [_make_divisible(ch * self.scale, 8) for ch in self.num_of_channels]\n        self.n = [1, 1, 2, 3, 4, 3, 3, 1]\n        self.s = [2, 1, 2, 2, 2, 1, 2, 1]\n        self.conv1 = nn.Conv2d(in_channels, self.c[0], kernel_size=3, bias=False, stride=self.s[0], padding=1)\n        self.bn1 = nn.BatchNorm2d(self.c[0])\n        self.bottlenecks = self._make_bottlenecks()\n\n        # Last convolution has 1280 output channels for scale <= 1\n        self.last_conv_out_ch = 1280 if self.scale <= 1 else _make_divisible(1280 * self.scale, 8)\n        self.conv_last = nn.Conv2d(self.c[-1], self.last_conv_out_ch, kernel_size=1, bias=False)\n        self.bn_last = nn.BatchNorm2d(self.last_conv_out_ch)\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(p=0.2, inplace=True)  # confirmed by paper authors\n        self.fc = nn.Linear(self.last_conv_out_ch, self.num_classes)\n        self.init_params()\n\n    def init_params(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode=\'fan_out\')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, std=0.001)\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n\n    def _make_stage(self, inplanes, outplanes, n, stride, t, stage):\n        modules = OrderedDict()\n        stage_name = ""LinearBottleneck{}"".format(stage)\n\n        # First module is the only one utilizing stride\n        first_module = LinearBottleneck(inplanes=inplanes, outplanes=outplanes, stride=stride, t=t,\n                                        activation=self.activation_type)\n        modules[stage_name + ""_0""] = first_module\n\n        # add more LinearBottleneck depending on number of repeats\n        for i in range(n - 1):\n            name = stage_name + ""_{}"".format(i + 1)\n            module = LinearBottleneck(inplanes=outplanes, outplanes=outplanes, stride=1, t=6,\n                                      activation=self.activation_type)\n            modules[name] = module\n\n        return nn.Sequential(modules)\n\n    def _make_bottlenecks(self):\n        modules = OrderedDict()\n        stage_name = ""Bottlenecks""\n\n        # First module is the only one with t=1\n        bottleneck1 = self._make_stage(inplanes=self.c[0], outplanes=self.c[1], n=self.n[1], stride=self.s[1], t=1,\n                                       stage=0)\n        modules[stage_name + ""_0""] = bottleneck1\n\n        # add more LinearBottleneck depending on number of repeats\n        for i in range(1, len(self.c) - 1):\n            name = stage_name + ""_{}"".format(i)\n            module = self._make_stage(inplanes=self.c[i], outplanes=self.c[i + 1], n=self.n[i + 1],\n                                      stride=self.s[i + 1],\n                                      t=self.t, stage=i)\n            modules[name] = module\n\n        return nn.Sequential(modules)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.activation(x)\n\n        x = self.bottlenecks(x)\n        x = self.conv_last(x)\n        x = self.bn_last(x)\n        x = self.activation(x)\n\n        # average pooling layer\n        x = self.avgpool(x)\n        x = self.dropout(x)\n\n        # flatten for input to fully-connected layer\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return F.log_softmax(x, dim=1) #TODO not needed(?)\n\n\nif __name__ == ""__main__"":\n    """"""Testing\n    """"""\n    model1 = MobileNet2()\n    print(model1)\n    model2 = MobileNet2(scale=0.35)\n    print(model2)\n    model3 = MobileNet2(in_channels=2, num_classes=10)\n    print(model3)\n    x = torch.randn(1, 2, 224, 224)\n    print(model3(x))\n    model4_size = 32 * 10\n    model4 = MobileNet2(input_size=model4_size, num_classes=10)\n    print(model4)\n    x2 = torch.randn(1, 3, model4_size, model4_size)\n    print(model4(x2))\n    model5 = MobileNet2(input_size=196, num_classes=10)\n    x3 = torch.randn(1, 3, 196, 196)\n    print(model5(x3))  # fail\n'"
run.py,5,"b'import os\nimport shutil\n\nimport matplotlib\nimport numpy as np\nimport torch\nimport torch.nn.parallel\nimport torch.optim\nimport torch.utils.data\nfrom tqdm import tqdm, trange\n\nmatplotlib.use(\'Agg\')\n\nfrom matplotlib import pyplot as plt\n\nfrom clr import CyclicLR\n\n\ndef train(model, loader, epoch, optimizer, criterion, device, dtype, batch_size, log_interval, scheduler):\n    model.train()\n    correct1, correct5 = 0, 0\n\n    for batch_idx, (data, target) in enumerate(tqdm(loader)):\n        if isinstance(scheduler, CyclicLR):\n            scheduler.batch_step()\n        data, target = data.to(device=device, dtype=dtype), target.to(device=device)\n\n        optimizer.zero_grad()\n        output = model(data)\n\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n        corr = correct(output, target, topk=(1, 5))\n        correct1 += corr[0]\n        correct5 += corr[1]\n\n        if batch_idx % log_interval == 0:\n            tqdm.write(\n                \'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}. \'\n                \'Top-1 accuracy: {:.2f}%({:.2f}%). \'\n                \'Top-5 accuracy: {:.2f}%({:.2f}%).\'.format(epoch, batch_idx, len(loader),\n                                                           100. * batch_idx / len(loader), loss.item(),\n                                                           100. * corr[0] / batch_size,\n                                                           100. * correct1 / (batch_size * (batch_idx + 1)),\n                                                           100. * corr[1] / batch_size,\n                                                           100. * correct5 / (batch_size * (batch_idx + 1))))\n    return loss.item(), correct1 / len(loader.dataset), correct5 / len(loader.dataset)\n\n\ndef test(model, loader, criterion, device, dtype):\n    model.eval()\n    test_loss = 0\n    correct1, correct5 = 0, 0\n\n    for batch_idx, (data, target) in enumerate(tqdm(loader)):\n        data, target = data.to(device=device, dtype=dtype), target.to(device=device)\n        with torch.no_grad():\n            output = model(data)\n            test_loss += criterion(output, target).item()  # sum up batch loss\n            corr = correct(output, target, topk=(1, 5))\n        correct1 += corr[0]\n        correct5 += corr[1]\n\n    test_loss /= len(loader)\n\n    tqdm.write(\n        \'\\nTest set: Average loss: {:.4f}, Top1: {}/{} ({:.2f}%), \'\n        \'Top5: {}/{} ({:.2f}%)\'.format(test_loss, int(correct1), len(loader.dataset),\n                                       100. * correct1 / len(loader.dataset), int(correct5),\n                                       len(loader.dataset), 100. * correct5 / len(loader.dataset)))\n    return test_loss, correct1 / len(loader.dataset), correct5 / len(loader.dataset)\n\n\ndef correct(output, target, topk=(1,)):\n    """"""Computes the correct@k for the specified values of k""""""\n    maxk = max(topk)\n\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t().type_as(target)\n    correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n    res = []\n    for k in topk:\n        correct_k = correct[:k].view(-1).float().sum(0).item()\n        res.append(correct_k)\n    return res\n\n\ndef save_checkpoint(state, is_best, filepath=\'./\', filename=\'checkpoint.pth.tar\'):\n    save_path = os.path.join(filepath, filename)\n    best_path = os.path.join(filepath, \'model_best.pth.tar\')\n    torch.save(state, save_path)\n    if is_best:\n        shutil.copyfile(save_path, best_path)\n\n\ndef find_bounds_clr(model, loader, optimizer, criterion, device, dtype, min_lr=8e-6, max_lr=8e-5, step_size=2000,\n                    mode=\'triangular\', save_path=\'.\'):\n    model.train()\n    correct1, correct5 = 0, 0\n    scheduler = CyclicLR(optimizer, base_lr=min_lr, max_lr=max_lr, step_size=step_size, mode=mode)\n    epoch_count = step_size // len(loader)  # Assuming step_size is multiple of batch per epoch\n    accuracy = []\n    for _ in trange(epoch_count):\n        for batch_idx, (data, target) in enumerate(tqdm(loader)):\n            if scheduler is not None:\n                scheduler.batch_step()\n            data, target = data.to(device=device, dtype=dtype), target.to(device=device)\n\n            optimizer.zero_grad()\n            output = model(data)\n\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n            corr = correct(output, target)\n            accuracy.append(corr[0] / data.shape[0])\n\n    lrs = np.linspace(min_lr, max_lr, step_size)\n    plt.plot(lrs, accuracy)\n    plt.show()\n    plt.savefig(os.path.join(save_path, \'find_bounds_clr.png\'))\n    np.save(os.path.join(save_path, \'acc.npy\'), accuracy)\n    return\n'"
