file_path,api_count,code
ACGAN.py,41,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass ACGAN(object):\n    model_name = ""ACGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.y_dim = 10         # dimension of code-vector (label)\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # code\n            self.len_discrete_code = 10  # categorical distribution (i.e. label)\n            self.len_continuous_code = 2  # gaussian distribution (e.g. rotation, thickness)\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def classifier(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)5c2s-(128)5c2s_BL-FC1024_BL-FC128_BL-FC12S\xe2\x80\x99\n        # All layers except the last two layers are shared by discriminator\n        with tf.variable_scope(""classifier"", reuse=reuse):\n\n            net = lrelu(bn(linear(x, 128, scope=\'c_fc1\'), is_training=is_training, scope=\'c_bn1\'))\n            out_logit = linear(net, self.y_dim, scope=\'c_fc2\')\n            out = tf.nn.softmax(out_logit)\n\n            return out, out_logit\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n\n            # merge noise and code\n            z = concat([z, y], 1)\n\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name=\'y\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n        ## 1. GAN Loss\n        # output of D for real images\n        D_real, D_real_logits, input4classifier_real = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, self.y, is_training=True, reuse=False)\n        D_fake, D_fake_logits, input4classifier_fake = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        ## 2. Information Loss\n        code_fake, code_logit_fake = self.classifier(input4classifier_fake, is_training=True, reuse=False)\n        code_real, code_logit_real = self.classifier(input4classifier_real, is_training=True, reuse=True)\n\n        # For real samples\n        q_real_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=code_logit_real, labels=self.y))\n\n        # For fake samples\n        q_fake_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=code_logit_fake, labels=self.y))\n\n        # get information loss\n        self.q_loss = q_fake_loss + q_real_loss\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n        q_vars = [var for var in t_vars if (\'d_\' in var.name) or (\'c_\' in var.name) or (\'g_\' in var.name)]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate * 5, beta1=self.beta1) \\\n                .minimize(self.g_loss, var_list=g_vars)\n            self.q_optim = tf.train.AdamOptimizer(self.learning_rate * 5, beta1=self.beta1) \\\n                .minimize(self.q_loss, var_list=q_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, self.y, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        q_loss_sum = tf.summary.scalar(""g_loss"", self.q_loss)\n        q_real_sum = tf.summary.scalar(""q_real_loss"", q_real_loss)\n        q_fake_sum = tf.summary.scalar(""q_fake_loss"", q_fake_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n        self.q_sum = tf.summary.merge([q_loss_sum, q_real_sum, q_fake_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n        self.test_codes = self.data_y[0:self.batch_size]\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_codes = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                                       feed_dict={self.inputs: batch_images, self.y: batch_codes,\n                                                                  self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G & Q network\n                _, summary_str_g, g_loss, _, summary_str_q, q_loss = self.sess.run(\n                    [self.g_optim, self.g_sum, self.g_loss, self.q_optim, self.q_sum, self.q_loss],\n                    feed_dict={self.z: batch_z, self.y: batch_codes, self.inputs: batch_images})\n                self.writer.add_summary(summary_str_g, counter)\n                self.writer.add_summary(summary_str_q, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z, self.y: self.test_codes})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w], \'./\' + check_folder(\n                        self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                        epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        """""" random noise, random discrete code, fixed continuous code """"""\n        y = np.random.choice(self.len_discrete_code, self.batch_size)\n        y_one_hot = np.zeros((self.batch_size, self.y_dim))\n        y_one_hot[np.arange(self.batch_size), y] = 1\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim*image_frame_dim,:,:,:], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n        """""" specified condition, random noise """"""\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n\n        for l in range(self.len_discrete_code):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n            save_images(samples[:image_frame_dim*image_frame_dim,:,:,:], [image_frame_dim, image_frame_dim],\n                        check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_class_%d.png\' % l)\n\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        """""" save merged images to check style-consistency """"""\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):\n            for c in range(self.len_discrete_code):\n                canvas[s * self.len_discrete_code + c, :, :, :] = all_samples[c * n_styles + s, :, :, :]\n\n        save_images(canvas, [n_styles, self.len_discrete_code],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes_style_by_style.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
BEGAN.py,36,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass BEGAN(object):\n    model_name = ""BEGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # BEGAN Parameter\n            self.gamma = 0.75\n            self.lamda = 0.001\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # It must be Auto-Encoder style architecture\n        # Architecture : (64)4c2s-FC32_BR-FC64*14*14_BR-(1)4dc2s_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = tf.nn.relu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            code = tf.nn.relu(bn(linear(net, 32, scope=\'d_fc6\'), is_training=is_training, scope=\'d_bn6\'))\n            net = tf.nn.relu(bn(linear(code, 64 * 14 * 14, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            net = tf.reshape(net, [self.batch_size, 14, 14, 64])\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'d_dc5\'))\n\n            # recon loss\n            recon_error = tf.sqrt(2 * tf.nn.l2_loss(out - x)) / self.batch_size\n            return out, recon_error, code\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" BEGAN variable """"""\n        self.k = tf.Variable(0., trainable=False)\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real_img, D_real_err, D_real_code = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake_img, D_fake_err, D_fake_code = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        self.d_loss = D_real_err - self.k*D_fake_err\n\n        # get loss for generator\n        self.g_loss = D_fake_err\n\n        # convergence metric\n        self.M = D_real_err + tf.abs(self.gamma*D_real_err - D_fake_err)\n\n        # operation for updating k\n        self.update_k = self.k.assign(\n            tf.clip_by_value(self.k + self.lamda*(self.gamma*D_real_err - D_fake_err), 0, 1))\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_error_real"", D_real_err)\n        d_loss_fake_sum = tf.summary.scalar(""d_error_fake"", D_fake_err)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n        M_sum = tf.summary.scalar(""M"", self.M)\n        k_sum = tf.summary.scalar(""k"", self.k)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n        self.p_sum = tf.summary.merge([M_sum, k_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update k\n                _, summary_str, M_value, k_value = self.sess.run([self.update_k, self.p_sum, self.M, self.k], feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f, M: %.8f, k: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss, M_value, k_value))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images, feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0\n'"
CGAN.py,33,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass CGAN(object):\n    model_name = ""CGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.y_dim = 10         # dimension of condition-vector (label)\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n\n    def discriminator(self, x, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            # merge image and label\n            y = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])\n            x = conv_cond_concat(x, y)\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n\n            # merge noise and label\n            z = concat([z, y], 1)\n\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name=\'y\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, self.y, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, self.y, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, self.y, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, self.y, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n        self.test_labels = self.data_y[0:self.batch_size]\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_labels = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                                       feed_dict={self.inputs: batch_images, self.y: batch_labels,\n                                                                  self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss],\n                                                       feed_dict={self.y: batch_labels, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z, self.y: self.test_labels})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n        y = np.random.choice(self.y_dim, self.batch_size)\n        y_one_hot = np.zeros((self.batch_size, self.y_dim))\n        y_one_hot[np.arange(self.batch_size), y] = 1\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n        """""" specified condition, random noise """"""\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n\n        for l in range(self.y_dim):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n            save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                        check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_class_%d.png\' % l)\n\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        """""" save merged images to check style-consistency """"""\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):\n            for c in range(self.y_dim):\n                canvas[s * self.y_dim + c, :, :, :] = all_samples[c * n_styles + s, :, :, :]\n\n        save_images(canvas, [n_styles, self.y_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes_style_by_style.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0\n'"
CVAE.py,30,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nimport prior_factory as prior\n\nclass CVAE(object):\n    model_name = ""CVAE""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.y_dim = 10         # dimension of condition-vector (label)\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    # Gaussian Encoder\n    def encoder(self, x, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""encoder"", reuse=reuse):\n\n            # merge image and label\n            y = tf.reshape(y, [self.batch_size, 1, 1, self.y_dim])\n            x = conv_cond_concat(x, y)\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'en_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'en_conv2\'), is_training=is_training, scope=\'en_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'en_fc3\'), is_training=is_training, scope=\'en_bn3\'))\n            gaussian_params = linear(net, 2 * self.z_dim, scope=\'en_fc4\')\n\n            # The mean parameter is unconstrained\n            mean = gaussian_params[:, :self.z_dim]\n            # The standard deviation must be positive. Parametrize with a softplus and\n            # add a small epsilon for numerical stability\n            stddev = 1e-6 + tf.nn.softplus(gaussian_params[:, self.z_dim:])\n\n        return mean, stddev\n\n    # Bernoulli decoder\n    def decoder(self, z, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""decoder"", reuse=reuse):\n\n            # merge noise and label\n            z = concat([z, y], 1)\n\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'de_fc1\'), is_training=is_training, scope=\'de_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'de_fc2\'), is_training=is_training, scope=\'de_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'de_dc3\'), is_training=is_training,\n                   scope=\'de_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'de_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name=\'y\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n        # encoding\n        mu, sigma = self.encoder(self.inputs, self.y,  is_training=True, reuse=False)\n\n        # sampling by re-parameterization technique\n        z = mu + sigma * tf.random_normal(tf.shape(mu), 0, 1, dtype=tf.float32)\n\n        # decoding\n        out = self.decoder(z, self.y, is_training=True, reuse=False)\n        self.out = tf.clip_by_value(out, 1e-8, 1 - 1e-8)\n\n        # loss\n        marginal_likelihood = tf.reduce_sum(self.inputs * tf.log(self.out) + (1 - self.inputs) * tf.log(1 - self.out), [1, 2])\n        KL_divergence = 0.5 * tf.reduce_sum(tf.square(mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1, [1])\n\n        self.neg_loglikelihood = -tf.reduce_mean(marginal_likelihood)\n        self.KL_divergence = tf.reduce_mean(KL_divergence)\n\n        ELBO = -self.neg_loglikelihood - self.KL_divergence\n\n        self.loss = -ELBO\n\n        """""" Training """"""\n        # optimizers\n        t_vars = tf.trainable_variables()\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.loss, var_list=t_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.decoder(self.z, self.y, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        nll_sum = tf.summary.scalar(""nll"", self.neg_loglikelihood)\n        kl_sum = tf.summary.scalar(""kl"", self.KL_divergence)\n        loss_sum = tf.summary.scalar(""loss"", self.loss)\n\n        # final summary operations\n        self.merged_summary_op = tf.summary.merge_all()\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = prior.gaussian(self.batch_size, self.z_dim)\n        self.test_labels = self.data_y[0:self.batch_size]\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_labels = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update autoencoder\n                _, summary_str, loss, nll_loss, kl_loss = self.sess.run([self.optim, self.merged_summary_op, self.loss, self.neg_loglikelihood, self.KL_divergence],\n                                               feed_dict={self.inputs: batch_images, self.y: batch_labels, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f, nll: %.8f, kl: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, loss, nll_loss, kl_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z, self.y: self.test_labels})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n        y = np.random.choice(self.y_dim, self.batch_size)\n        y_one_hot = np.zeros((self.batch_size, self.y_dim))\n        y_one_hot[np.arange(self.batch_size), y] = 1\n\n        z_sample = prior.gaussian(self.batch_size, self.z_dim)\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n        """""" specified condition, random noise """"""\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n\n        for l in range(self.y_dim):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n            save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                        check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_class_%d.png\' % l)\n\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        """""" save merged images to check style-consistency """"""\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):\n            for c in range(self.y_dim):\n                canvas[s * self.y_dim + c, :, :, :] = all_samples[c * n_styles + s, :, :, :]\n\n        save_images(canvas, [n_styles, self.y_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes_style_by_style.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
DRAGAN.py,36,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass DRAGAN(object):\n    model_name = ""DRAGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # DRAGAN parameter\n            self.lambd = 0.25       # The higher value, the more stable, but the slower convergence\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def get_perturbed_batch(self, minibatch):\n        return minibatch + 0.5 * minibatch.std() * np.random.random(minibatch.shape)\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n        self.inputs_p = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_perturbed_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        """""" DRAGAN Loss (Gradient penalty) """"""\n        # This is borrowed from https://github.com/kodalinaveen3/DRAGAN/blob/master/DRAGAN.ipynb\n        alpha = tf.random_uniform(shape=self.inputs.get_shape(), minval=0.,maxval=1.)\n        differences = self.inputs_p - self.inputs  # This is different from WGAN-GP\n        interpolates = self.inputs + (alpha * differences)\n        _,D_inter,_=self.discriminator(interpolates, is_training=True, reuse=True)\n        gradients = tf.gradients(D_inter, [interpolates])[0]\n        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n        gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n        self.d_loss += self.lambd * gradient_penalty\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_images_p = self.get_perturbed_batch(batch_images)\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.inputs_p: batch_images_p, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
EBGAN.py,34,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass EBGAN(object):\n    model_name = ""EBGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # EBGAN Parameter\n            self.pt_loss_weight = 0.1\n            self.margin = max(1,self.batch_size/64.)        # margin for loss function\n            # usually margin of 1 is enough, but for large batch size it must be larger than 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    # borrowed from https://github.com/shekkizh/EBGAN.tensorflow/blob/master/EBGAN/Faces_EBGAN.py\n    def pullaway_loss(self, embeddings):\n        """"""\n        Pull Away loss calculation\n        :param embeddings: The embeddings to be orthogonalized for varied faces. Shape [batch_size, embeddings_dim]\n        :return: pull away term loss\n        """"""\n        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n        normalized_embeddings = embeddings / norm\n        similarity = tf.matmul(\n            normalized_embeddings, normalized_embeddings, transpose_b=True)\n        batch_size = tf.cast(tf.shape(embeddings)[0], tf.float32)\n        pt_loss = (tf.reduce_sum(similarity) - batch_size) / (batch_size * (batch_size - 1))\n        return pt_loss\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # It must be Auto-Encoder style architecture\n        # Architecture : (64)4c2s-FC32-FC64*14*14_BR-(1)4dc2s_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = tf.nn.relu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            code = (linear(net, 32, scope=\'d_fc6\')) # bn and relu are excluded since code is used in pullaway_loss\n            net = tf.nn.relu(bn(linear(code, 64 * 14 * 14, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            net = tf.reshape(net, [self.batch_size, 14, 14, 64])\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'d_dc5\'))\n\n            # recon loss\n            recon_error = tf.sqrt(2 * tf.nn.l2_loss(out - x)) / self.batch_size\n            return out, recon_error, code\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real_img, D_real_err, D_real_code = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake_img, D_fake_err, D_fake_code = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        self.d_loss = D_real_err + tf.maximum(self.margin - D_fake_err,0)\n\n        # get loss for generator\n        self.g_loss = D_fake_err + self.pt_loss_weight*self.pullaway_loss(D_fake_code)\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_error_real"", D_real_err)\n        d_loss_fake_sum = tf.summary.scalar(""d_error_fake"", D_fake_err)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
GAN.py,31,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass GAN(object):\n    model_name = ""GAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images, feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0\n'"
LSGAN.py,30,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass LSGAN(object):\n    model_name = ""LSGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def mse_loss(self, pred, data):\n        loss_val = tf.sqrt(2 * tf.nn.l2_loss(pred - data)) / self.batch_size\n        return loss_val\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(self.mse_loss(D_real_logits, tf.ones_like(D_real_logits)))\n        d_loss_fake = tf.reduce_mean(self.mse_loss(D_fake_logits, tf.zeros_like(D_fake_logits)))\n\n        self.d_loss = 0.5*(d_loss_real + d_loss_fake)\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(self.mse_loss(D_fake_logits, tf.ones_like(D_fake_logits)))\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        # weight clipping\n        self.clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in d_vars]\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, _, summary_str, d_loss = self.sess.run([self.d_optim, self.clip_D, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
VAE.py,28,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nimport prior_factory as prior\n\nclass VAE(object):\n    model_name = ""VAE""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    # Gaussian Encoder\n    def encoder(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC62*4\n        with tf.variable_scope(""encoder"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'en_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'en_conv2\'), is_training=is_training, scope=\'en_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'en_fc3\'), is_training=is_training, scope=\'en_bn3\'))\n            gaussian_params = linear(net, 2 * self.z_dim, scope=\'en_fc4\')\n\n            # The mean parameter is unconstrained\n            mean = gaussian_params[:, :self.z_dim]\n            # The standard deviation must be positive. Parametrize with a softplus and\n            # add a small epsilon for numerical stability\n            stddev = 1e-6 + tf.nn.softplus(gaussian_params[:, self.z_dim:])\n\n        return mean, stddev\n\n    # Bernoulli decoder\n    def decoder(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""decoder"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'de_fc1\'), is_training=is_training, scope=\'de_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'de_fc2\'), is_training=is_training, scope=\'de_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'de_dc3\'), is_training=is_training,\n                   scope=\'de_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'de_dc4\'))\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n        # encoding\n        self.mu, sigma = self.encoder(self.inputs, is_training=True, reuse=False)        \n\n        # sampling by re-parameterization technique\n        z = self.mu + sigma * tf.random_normal(tf.shape(self.mu), 0, 1, dtype=tf.float32)\n\n        # decoding\n        out = self.decoder(z, is_training=True, reuse=False)\n        self.out = tf.clip_by_value(out, 1e-8, 1 - 1e-8)\n\n        # loss\n        marginal_likelihood = tf.reduce_sum(self.inputs * tf.log(self.out) + (1 - self.inputs) * tf.log(1 - self.out),\n                                            [1, 2])\n        KL_divergence = 0.5 * tf.reduce_sum(tf.square(self.mu) + tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1, [1])\n\n        self.neg_loglikelihood = -tf.reduce_mean(marginal_likelihood)\n        self.KL_divergence = tf.reduce_mean(KL_divergence)\n\n        ELBO = -self.neg_loglikelihood - self.KL_divergence\n\n        self.loss = -ELBO\n\n        """""" Training """"""\n        # optimizers\n        t_vars = tf.trainable_variables()\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.loss, var_list=t_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.decoder(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        nll_sum = tf.summary.scalar(""nll"", self.neg_loglikelihood)\n        kl_sum = tf.summary.scalar(""kl"", self.KL_divergence)\n        loss_sum = tf.summary.scalar(""loss"", self.loss)\n\n        # final summary operations\n        self.merged_summary_op = tf.summary.merge_all()\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = prior.gaussian(self.batch_size, self.z_dim)\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = prior.gaussian(self.batch_size, self.z_dim)\n\n                # update autoencoder\n                _, summary_str, loss, nll_loss, kl_loss = self.sess.run([self.optim, self.merged_summary_op, self.loss, self.neg_loglikelihood, self.KL_divergence],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f, nll: %.8f, kl: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, loss, nll_loss, kl_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = prior.gaussian(self.batch_size, self.z_dim)\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(\n                        self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n        """""" learned manifold """"""\n        if self.z_dim == 2:\n            assert self.z_dim == 2\n\n            z_tot = None\n            id_tot = None\n            for idx in range(0, 100):\n                #randomly sampling\n                id = np.random.randint(0,self.num_batches)\n                batch_images = self.data_X[id * self.batch_size:(id + 1) * self.batch_size]\n                batch_labels = self.data_y[id * self.batch_size:(id + 1) * self.batch_size]\n\n                z = self.sess.run(self.mu, feed_dict={self.inputs: batch_images})\n\n                if idx == 0:\n                    z_tot = z\n                    id_tot = batch_labels\n                else:\n                    z_tot = np.concatenate((z_tot, z), axis=0)\n                    id_tot = np.concatenate((id_tot, batch_labels), axis=0)\n\n            save_scattered_image(z_tot, id_tot, -4, 4, name=check_folder(\n                self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_learned_manifold.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
WGAN.py,28,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass WGAN(object):\n    model_name = ""WGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # WGAN parameter\n            self.disc_iters = 1     # The number of critic iterations for one-step of generator\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = - tf.reduce_mean(D_real_logits)\n        d_loss_fake = tf.reduce_mean(D_fake_logits)\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = - d_loss_fake\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        # weight clipping\n        self.clip_D = [p.assign(tf.clip_by_value(p, -0.01, 0.01)) for p in d_vars]\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, _, summary_str, d_loss = self.sess.run([self.d_optim, self.clip_D, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                if (counter - 1) % self.disc_iters == 0:\n                    _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                    self.writer.add_summary(summary_str, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
WGAN_GP.py,31,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass WGAN_GP(object):\n    model_name = ""WGAN_GP""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.c_dim = 1\n\n            # WGAN_GP parameter\n            self.lambd = 0.25       # The higher value, the more stable, but the slower convergence\n            self.disc_iters = 1     # The number of critic iterations for one-step of generator\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, is_training=True, reuse=False)\n        D_fake, D_fake_logits, _ = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = - tf.reduce_mean(D_real_logits)\n        d_loss_fake = tf.reduce_mean(D_fake_logits)\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = - d_loss_fake\n\n        """""" Gradient Penalty """"""\n        # This is borrowed from https://github.com/kodalinaveen3/DRAGAN/blob/master/DRAGAN.ipynb\n        alpha = tf.random_uniform(shape=self.inputs.get_shape(), minval=0.,maxval=1.)\n        differences = G - self.inputs # This is different from MAGAN\n        interpolates = self.inputs + (alpha * differences)\n        _,D_inter,_=self.discriminator(interpolates, is_training=True, reuse=True)\n        gradients = tf.gradients(D_inter, [interpolates])[0]\n        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n        gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n        self.d_loss += self.lambd * gradient_penalty\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                      .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate*5, beta1=self.beta1) \\\n                      .minimize(self.g_loss, var_list=g_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                               feed_dict={self.inputs: batch_images, self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G network\n                if (counter-1) % self.disc_iters == 0:\n                    batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n                    _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss], feed_dict={self.z: batch_z})\n                    self.writer.add_summary(summary_str, counter)\n\n                counter += 1\n\n                # display training status\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random condition, random noise """"""\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0'"
infoGAN.py,41,"b'#-*- coding: utf-8 -*-\nfrom __future__ import division\nimport os\nimport time\nimport tensorflow as tf\nimport numpy as np\n\nfrom ops import *\nfrom utils import *\n\nclass infoGAN(object):\n    model_name = ""infoGAN""     # name for checkpoint\n\n    def __init__(self, sess, epoch, batch_size, z_dim, dataset_name, checkpoint_dir, result_dir, log_dir, SUPERVISED=True):\n        self.sess = sess\n        self.dataset_name = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.result_dir = result_dir\n        self.log_dir = log_dir\n        self.epoch = epoch\n        self.batch_size = batch_size\n\n        if dataset_name == \'mnist\' or dataset_name == \'fashion-mnist\':\n            # parameters\n            self.input_height = 28\n            self.input_width = 28\n            self.output_height = 28\n            self.output_width = 28\n\n            self.z_dim = z_dim         # dimension of noise-vector\n            self.y_dim = 12         # dimension of code-vector (label+two features)\n            self.c_dim = 1\n\n            self.SUPERVISED = SUPERVISED # if it is true, label info is directly used for code\n\n            # train\n            self.learning_rate = 0.0002\n            self.beta1 = 0.5\n\n            # test\n            self.sample_num = 64  # number of generated images to be saved\n\n            # code\n            self.len_discrete_code = 10  # categorical distribution (i.e. label)\n            self.len_continuous_code = 2  # gaussian distribution (e.g. rotation, thickness)\n\n            # load mnist\n            self.data_X, self.data_y = load_mnist(self.dataset_name)\n\n            # get number of batches for a single epoch\n            self.num_batches = len(self.data_X) // self.batch_size\n        else:\n            raise NotImplementedError\n\n    def classifier(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)5c2s-(128)5c2s_BL-FC1024_BL-FC128_BL-FC12S\xe2\x80\x99\n        # All layers except the last two layers are shared by discriminator\n        # Number of nodes in the last layer is reduced by half. It gives better results.\n        with tf.variable_scope(""classifier"", reuse=reuse):\n\n            net = lrelu(bn(linear(x, 64, scope=\'c_fc1\'), is_training=is_training, scope=\'c_bn1\'))\n            out_logit = linear(net, self.y_dim, scope=\'c_fc2\')\n            out = tf.nn.softmax(out_logit)\n\n            return out, out_logit\n\n    def discriminator(self, x, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n        with tf.variable_scope(""discriminator"", reuse=reuse):\n\n            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name=\'d_conv1\'))\n            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name=\'d_conv2\'), is_training=is_training, scope=\'d_bn2\'))\n            net = tf.reshape(net, [self.batch_size, -1])\n            net = lrelu(bn(linear(net, 1024, scope=\'d_fc3\'), is_training=is_training, scope=\'d_bn3\'))\n            out_logit = linear(net, 1, scope=\'d_fc4\')\n            out = tf.nn.sigmoid(out_logit)\n\n            return out, out_logit, net\n\n    def generator(self, z, y, is_training=True, reuse=False):\n        # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n        # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n        with tf.variable_scope(""generator"", reuse=reuse):\n\n            # merge noise and code\n            z = concat([z, y], 1)\n\n            net = tf.nn.relu(bn(linear(z, 1024, scope=\'g_fc1\'), is_training=is_training, scope=\'g_bn1\'))\n            net = tf.nn.relu(bn(linear(net, 128 * 7 * 7, scope=\'g_fc2\'), is_training=is_training, scope=\'g_bn2\'))\n            net = tf.reshape(net, [self.batch_size, 7, 7, 128])\n            net = tf.nn.relu(\n                bn(deconv2d(net, [self.batch_size, 14, 14, 64], 4, 4, 2, 2, name=\'g_dc3\'), is_training=is_training,\n                   scope=\'g_bn3\'))\n\n            out = tf.nn.sigmoid(deconv2d(net, [self.batch_size, 28, 28, 1], 4, 4, 2, 2, name=\'g_dc4\'))\n\n            return out\n\n    def build_model(self):\n        # some parameters\n        image_dims = [self.input_height, self.input_width, self.c_dim]\n        bs = self.batch_size\n\n        """""" Graph Input """"""\n        # images\n        self.inputs = tf.placeholder(tf.float32, [bs] + image_dims, name=\'real_images\')\n\n        # labels\n        self.y = tf.placeholder(tf.float32, [bs, self.y_dim], name=\'y\')\n\n        # noises\n        self.z = tf.placeholder(tf.float32, [bs, self.z_dim], name=\'z\')\n\n        """""" Loss Function """"""\n        ## 1. GAN Loss\n        # output of D for real images\n        D_real, D_real_logits, _ = self.discriminator(self.inputs, is_training=True, reuse=False)\n\n        # output of D for fake images\n        G = self.generator(self.z, self.y, is_training=True, reuse=False)\n        D_fake, D_fake_logits, input4classifier_fake = self.discriminator(G, is_training=True, reuse=True)\n\n        # get loss for discriminator\n        d_loss_real = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n        d_loss_fake = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n\n        self.d_loss = d_loss_real + d_loss_fake\n\n        # get loss for generator\n        self.g_loss = tf.reduce_mean(\n            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n\n        ## 2. Information Loss\n        code_fake, code_logit_fake = self.classifier(input4classifier_fake, is_training=True, reuse=False)\n\n        # discrete code : categorical\n        disc_code_est = code_logit_fake[:, :self.len_discrete_code]\n        disc_code_tg = self.y[:, :self.len_discrete_code]\n        q_disc_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=disc_code_est, labels=disc_code_tg))\n\n        # continuous code : gaussian\n        cont_code_est = code_logit_fake[:, self.len_discrete_code:]\n        cont_code_tg = self.y[:, self.len_discrete_code:]\n        q_cont_loss = tf.reduce_mean(tf.reduce_sum(tf.square(cont_code_tg - cont_code_est), axis=1))\n\n        # get information loss\n        self.q_loss = q_disc_loss + q_cont_loss\n\n        """""" Training """"""\n        # divide trainable variables into a group for D and a group for G\n        t_vars = tf.trainable_variables()\n        d_vars = [var for var in t_vars if \'d_\' in var.name]\n        g_vars = [var for var in t_vars if \'g_\' in var.name]\n        q_vars = [var for var in t_vars if (\'d_\' in var.name) or (\'c_\' in var.name) or (\'g_\' in var.name)]\n\n        # optimizers\n        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n            self.d_optim = tf.train.AdamOptimizer(self.learning_rate, beta1=self.beta1) \\\n                .minimize(self.d_loss, var_list=d_vars)\n            self.g_optim = tf.train.AdamOptimizer(self.learning_rate * 5, beta1=self.beta1) \\\n                .minimize(self.g_loss, var_list=g_vars)\n            self.q_optim = tf.train.AdamOptimizer(self.learning_rate * 5, beta1=self.beta1) \\\n                .minimize(self.q_loss, var_list=q_vars)\n\n        """""""" Testing """"""\n        # for test\n        self.fake_images = self.generator(self.z, self.y, is_training=False, reuse=True)\n\n        """""" Summary """"""\n        d_loss_real_sum = tf.summary.scalar(""d_loss_real"", d_loss_real)\n        d_loss_fake_sum = tf.summary.scalar(""d_loss_fake"", d_loss_fake)\n        d_loss_sum = tf.summary.scalar(""d_loss"", self.d_loss)\n        g_loss_sum = tf.summary.scalar(""g_loss"", self.g_loss)\n\n        q_loss_sum = tf.summary.scalar(""g_loss"", self.q_loss)\n        q_disc_sum = tf.summary.scalar(""q_disc_loss"", q_disc_loss)\n        q_cont_sum = tf.summary.scalar(""q_cont_loss"", q_cont_loss)\n\n        # final summary operations\n        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n        self.q_sum = tf.summary.merge([q_loss_sum, q_disc_sum, q_cont_sum])\n\n    def train(self):\n\n        # initialize all variables\n        tf.global_variables_initializer().run()\n\n        # graph inputs for visualize training results\n        self.sample_z = np.random.uniform(-1, 1, size=(self.batch_size , self.z_dim))\n        self.test_labels = self.data_y[0:self.batch_size]\n        self.test_codes = np.concatenate((self.test_labels, np.zeros([self.batch_size, self.len_continuous_code])),\n                                           axis=1)\n\n        # saver to save model\n        self.saver = tf.train.Saver()\n\n        # summary writer\n        self.writer = tf.summary.FileWriter(self.log_dir + \'/\' + self.model_name, self.sess.graph)\n\n        # restore check-point if it exits\n        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n        if could_load:\n            start_epoch = (int)(checkpoint_counter / self.num_batches)\n            start_batch_id = checkpoint_counter - start_epoch * self.num_batches\n            counter = checkpoint_counter\n            print("" [*] Load SUCCESS"")\n        else:\n            start_epoch = 0\n            start_batch_id = 0\n            counter = 1\n            print("" [!] Load failed..."")\n\n        # loop for epoch\n        start_time = time.time()\n        for epoch in range(start_epoch, self.epoch):\n\n            # get batch data\n            for idx in range(start_batch_id, self.num_batches):\n                batch_images = self.data_X[idx*self.batch_size:(idx+1)*self.batch_size]\n\n                # generate code\n                if self.SUPERVISED == True:\n                    batch_labels = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n                else:\n                    batch_labels = np.random.multinomial(1,\n                                                         self.len_discrete_code * [float(1.0 / self.len_discrete_code)],\n                                                         size=[self.batch_size])\n\n                batch_codes = np.concatenate((batch_labels, np.random.uniform(-1, 1, size=(self.batch_size, 2))),\n                                             axis=1)\n\n                batch_z = np.random.uniform(-1, 1, [self.batch_size, self.z_dim]).astype(np.float32)\n\n                # update D network\n                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n                                                       feed_dict={self.inputs: batch_images, self.y: batch_codes,\n                                                                  self.z: batch_z})\n                self.writer.add_summary(summary_str, counter)\n\n                # update G and Q network\n                _, summary_str_g, g_loss, _, summary_str_q, q_loss = self.sess.run(\n                    [self.g_optim, self.g_sum, self.g_loss, self.q_optim, self.q_sum, self.q_loss],\n                    feed_dict={self.inputs: batch_images, self.z: batch_z, self.y: batch_codes})\n                self.writer.add_summary(summary_str_g, counter)\n                self.writer.add_summary(summary_str_q, counter)\n\n                # display training status\n                counter += 1\n                print(""Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f"" \\\n                      % (epoch, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n\n                # save training results for every 300 steps\n                if np.mod(counter, 300) == 0:\n                    samples = self.sess.run(self.fake_images,\n                                            feed_dict={self.z: self.sample_z, self.y: self.test_codes})\n                    tot_num_samples = min(self.sample_num, self.batch_size)\n                    manifold_h = int(np.floor(np.sqrt(tot_num_samples)))\n                    manifold_w = int(np.floor(np.sqrt(tot_num_samples)))\n                    save_images(samples[:manifold_h * manifold_w, :, :, :], [manifold_h, manifold_w],\n                                \'./\' + check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_train_{:02d}_{:04d}.png\'.format(\n                                    epoch, idx))\n\n            # After an epoch, start_batch_id is set to zero\n            # non-zero value is only for the first epoch after loading pre-trained model\n            start_batch_id = 0\n\n            # save model\n            self.save(self.checkpoint_dir, counter)\n\n            # show temporal results\n            self.visualize_results(epoch)\n\n        # save model for final step\n        self.save(self.checkpoint_dir, counter)\n\n    def visualize_results(self, epoch):\n        tot_num_samples = min(self.sample_num, self.batch_size)\n        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples)))\n\n        """""" random noise, random discrete code, fixed continuous code """"""\n        y = np.random.choice(self.len_discrete_code, self.batch_size)\n        y_one_hot = np.zeros((self.batch_size, self.y_dim))\n        y_one_hot[np.arange(self.batch_size), y] = 1\n\n        z_sample = np.random.uniform(-1, 1, size=(self.batch_size, self.z_dim))\n\n        samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n\n        save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes.png\')\n\n        """""" specified condition, random noise """"""\n        n_styles = 10  # must be less than or equal to self.batch_size\n\n        np.random.seed()\n        si = np.random.choice(self.batch_size, n_styles)\n\n        for l in range(self.len_discrete_code):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            samples = self.sess.run(self.fake_images, feed_dict={self.z: z_sample, self.y: y_one_hot})\n            # save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n            #             check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_class_%d.png\' % l)\n\n            samples = samples[si, :, :, :]\n\n            if l == 0:\n                all_samples = samples\n            else:\n                all_samples = np.concatenate((all_samples, samples), axis=0)\n\n        """""" save merged images to check style-consistency """"""\n        canvas = np.zeros_like(all_samples)\n        for s in range(n_styles):\n            for c in range(self.len_discrete_code):\n                canvas[s * self.len_discrete_code + c, :, :, :] = all_samples[c * n_styles + s, :, :, :]\n\n        save_images(canvas, [n_styles, self.len_discrete_code],\n                    check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_all_classes_style_by_style.png\')\n\n        """""" fixed noise """"""\n        assert self.len_continuous_code == 2\n\n        c1 = np.linspace(-1, 1, image_frame_dim)\n        c2 = np.linspace(-1, 1, image_frame_dim)\n        xv, yv = np.meshgrid(c1, c2)\n        xv = xv[:image_frame_dim,:image_frame_dim]\n        yv = yv[:image_frame_dim, :image_frame_dim]\n\n        c1 = xv.flatten()\n        c2 = yv.flatten()\n\n        z_fixed = np.zeros([self.batch_size, self.z_dim])\n\n        for l in range(self.len_discrete_code):\n            y = np.zeros(self.batch_size, dtype=np.int64) + l\n            y_one_hot = np.zeros((self.batch_size, self.y_dim))\n            y_one_hot[np.arange(self.batch_size), y] = 1\n\n            y_one_hot[np.arange(image_frame_dim*image_frame_dim), self.len_discrete_code] = c1\n            y_one_hot[np.arange(image_frame_dim*image_frame_dim), self.len_discrete_code+1] = c2\n\n            samples = self.sess.run(self.fake_images,\n                                    feed_dict={ self.z: z_fixed, self.y: y_one_hot})\n\n            save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n                        check_folder(self.result_dir + \'/\' + self.model_dir) + \'/\' + self.model_name + \'_epoch%03d\' % epoch + \'_test_class_c1c2_%d.png\' % l)\n\n    @property\n    def model_dir(self):\n        return ""{}_{}_{}_{}"".format(\n            self.model_name, self.dataset_name,\n            self.batch_size, self.z_dim)\n\n    def save(self, checkpoint_dir, step):\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        if not os.path.exists(checkpoint_dir):\n            os.makedirs(checkpoint_dir)\n\n        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+\'.model\'), global_step=step)\n\n    def load(self, checkpoint_dir):\n        import re\n        print("" [*] Reading checkpoints..."")\n        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n\n        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n        if ckpt and ckpt.model_checkpoint_path:\n            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n            counter = int(next(re.finditer(""(\\d+)(?!.*\\d)"",ckpt_name)).group(0))\n            print("" [*] Success to read {}"".format(ckpt_name))\n            return True, counter\n        else:\n            print("" [*] Failed to find a checkpoint"")\n            return False, 0\n'"
main.py,1,"b'import os\n\n## GAN Variants\nfrom GAN import GAN\nfrom CGAN import CGAN\nfrom infoGAN import infoGAN\nfrom ACGAN import ACGAN\nfrom EBGAN import EBGAN\nfrom WGAN import WGAN\nfrom WGAN_GP import WGAN_GP\nfrom DRAGAN import DRAGAN\nfrom LSGAN import LSGAN\nfrom BEGAN import BEGAN\n\n## VAE Variants\nfrom VAE import VAE\nfrom CVAE import CVAE\n\nfrom utils import show_all_variables\nfrom utils import check_folder\n\nimport tensorflow as tf\nimport argparse\n\n""""""parsing and configuration""""""\ndef parse_args():\n    desc = ""Tensorflow implementation of GAN collections""\n    parser = argparse.ArgumentParser(description=desc)\n\n    parser.add_argument(\'--gan_type\', type=str, default=\'GAN\',\n                        choices=[\'GAN\', \'CGAN\', \'infoGAN\', \'ACGAN\', \'EBGAN\', \'BEGAN\', \'WGAN\', \'WGAN_GP\', \'DRAGAN\', \'LSGAN\', \'VAE\', \'CVAE\'],\n                        help=\'The type of GAN\', required=True)\n    parser.add_argument(\'--dataset\', type=str, default=\'mnist\', choices=[\'mnist\', \'fashion-mnist\', \'celebA\'],\n                        help=\'The name of dataset\')\n    parser.add_argument(\'--epoch\', type=int, default=20, help=\'The number of epochs to run\')\n    parser.add_argument(\'--batch_size\', type=int, default=64, help=\'The size of batch\')\n    parser.add_argument(\'--z_dim\', type=int, default=62, help=\'Dimension of noise vector\')\n    parser.add_argument(\'--checkpoint_dir\', type=str, default=\'checkpoint\',\n                        help=\'Directory name to save the checkpoints\')\n    parser.add_argument(\'--result_dir\', type=str, default=\'results\',\n                        help=\'Directory name to save the generated images\')\n    parser.add_argument(\'--log_dir\', type=str, default=\'logs\',\n                        help=\'Directory name to save training logs\')\n\n    return check_args(parser.parse_args())\n\n""""""checking arguments""""""\ndef check_args(args):\n    # --checkpoint_dir\n    check_folder(args.checkpoint_dir)\n\n    # --result_dir\n    check_folder(args.result_dir)\n\n    # --result_dir\n    check_folder(args.log_dir)\n\n    # --epoch\n    assert args.epoch >= 1, \'number of epochs must be larger than or equal to one\'\n\n    # --batch_size\n    assert args.batch_size >= 1, \'batch size must be larger than or equal to one\'\n\n    # --z_dim\n    assert args.z_dim >= 1, \'dimension of noise vector must be larger than or equal to one\'\n\n    return args\n\n""""""main""""""\ndef main():\n    # parse arguments\n    args = parse_args()\n    if args is None:\n      exit()\n\n    # open session\n    models = [GAN, CGAN, infoGAN, ACGAN, EBGAN, WGAN, WGAN_GP, DRAGAN,\n              LSGAN, BEGAN, VAE, CVAE]\n    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n        # declare instance for GAN\n\n        gan = None\n        for model in models:\n            if args.gan_type == model.model_name:\n                gan = model(sess,\n                            epoch=args.epoch,\n                            batch_size=args.batch_size,\n                            z_dim=args.z_dim,\n                            dataset_name=args.dataset,\n                            checkpoint_dir=args.checkpoint_dir,\n                            result_dir=args.result_dir,\n                            log_dir=args.log_dir)\n        if gan is None:\n            raise Exception(""[!] There is no option for "" + args.gan_type)\n\n        # build graph\n        gan.build_model()\n\n        # show network architecture\n        show_all_variables()\n\n        # launch the graph in a session\n        gan.train()\n        print("" [*] Training finished!"")\n\n        # visualize learned generator\n        gan.visualize_results(args.epoch-1)\n        print("" [*] Testing finished!"")\n\nif __name__ == \'__main__\':\n    main()\n'"
ops.py,25,"b'""""""\nMost codes from https://github.com/carpedm20/DCGAN-tensorflow\n""""""\nimport math\nimport numpy as np \nimport tensorflow as tf\n\nfrom tensorflow.python.framework import ops\n\nfrom utils import *\n\nif ""concat_v2"" in dir(tf):\n    def concat(tensors, axis, *args, **kwargs):\n        return tf.concat_v2(tensors, axis, *args, **kwargs)\nelse:\n    def concat(tensors, axis, *args, **kwargs):\n        return tf.concat(tensors, axis, *args, **kwargs)\n\ndef bn(x, is_training, scope):\n    return tf.contrib.layers.batch_norm(x,\n                                        decay=0.9,\n                                        updates_collections=None,\n                                        epsilon=1e-5,\n                                        scale=True,\n                                        is_training=is_training,\n                                        scope=scope)\n\ndef conv_out_size_same(size, stride):\n    return int(math.ceil(float(size) / float(stride)))\n\ndef conv_cond_concat(x, y):\n    """"""Concatenate conditioning vector on feature map axis.""""""\n    x_shapes = x.get_shape()\n    y_shapes = y.get_shape()\n    return concat([x, y*tf.ones([x_shapes[0], x_shapes[1], x_shapes[2], y_shapes[3]])], 3)\n\ndef conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=""conv2d""):\n    with tf.variable_scope(name):\n        w = tf.get_variable(\'w\', [k_h, k_w, input_.get_shape()[-1], output_dim],\n              initializer=tf.truncated_normal_initializer(stddev=stddev))\n        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding=\'SAME\')\n\n        biases = tf.get_variable(\'biases\', [output_dim], initializer=tf.constant_initializer(0.0))\n        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n\n        return conv\n\ndef deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, name=""deconv2d"", stddev=0.02, with_w=False):\n    with tf.variable_scope(name):\n        # filter : [height, width, output_channels, in_channels]\n        w = tf.get_variable(\'w\', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n                            initializer=tf.random_normal_initializer(stddev=stddev))\n\n        try:\n            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n\n        # Support for verisons of TensorFlow before 0.7.0\n        except AttributeError:\n            deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n\n        biases = tf.get_variable(\'biases\', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n\n        if with_w:\n            return deconv, w, biases\n        else:\n            return deconv\n\ndef lrelu(x, leak=0.2, name=""lrelu""):\n    return tf.maximum(x, leak*x)\n\ndef linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n    shape = input_.get_shape().as_list()\n\n    with tf.variable_scope(scope or ""Linear""):\n        matrix = tf.get_variable(""Matrix"", [shape[1], output_size], tf.float32,\n                 tf.random_normal_initializer(stddev=stddev))\n        bias = tf.get_variable(""bias"", [output_size],\n        initializer=tf.constant_initializer(bias_start))\n        if with_w:\n            return tf.matmul(input_, matrix) + bias, matrix, bias\n        else:\n            return tf.matmul(input_, matrix) + bias\n'"
prior_factory.py,0,"b'""""""\nMost codes from https://github.com/musyoku/adversarial-autoencoder/blob/master/sampler.py\n""""""\n\nimport numpy as np\nfrom math import sin,cos,sqrt\n\ndef onehot_categorical(batch_size, n_labels):\n    y = np.zeros((batch_size, n_labels), dtype=np.float32)\n    indices = np.random.randint(0, n_labels, batch_size)\n    for b in range(batch_size):\n        y[b, indices[b]] = 1\n    return y\n\ndef uniform(batch_size, n_dim, n_labels=10, minv=-1, maxv=1, label_indices=None):\n    if label_indices is not None:\n        if n_dim != 2:\n            raise Exception(""n_dim must be 2."")\n\n        def sample(label, n_labels):\n            num = int(np.ceil(np.sqrt(n_labels)))\n            size = (maxv-minv)*1.0/num\n            x, y = np.random.uniform(-size/2, size/2, (2,))\n            i = label / num\n            j = label % num\n            x += j*size+minv+0.5*size\n            y += i*size+minv+0.5*size\n            return np.array([x, y]).reshape((2,))\n\n        z = np.empty((batch_size, n_dim), dtype=np.float32)\n        for batch in range(batch_size):\n            for zi in range((int)(n_dim/2)):\n                    z[batch, zi*2:zi*2+2] = sample(label_indices[batch], n_labels)\n    else:\n        z = np.random.uniform(minv, maxv, (batch_size, n_dim)).astype(np.float32)\n    return z\n\ndef gaussian(batch_size, n_dim, mean=0, var=1, n_labels=10, use_label_info=False):\n    if use_label_info:\n        if n_dim != 2:\n            raise Exception(""n_dim must be 2."")\n\n        def sample(n_labels):\n            x, y = np.random.normal(mean, var, (2,))\n            angle = np.angle((x-mean) + 1j*(y-mean), deg=True)\n\n            label = ((int)(n_labels*angle))//360\n\n            if label<0:\n                label+=n_labels\n\n            return np.array([x, y]).reshape((2,)), label\n\n        z = np.empty((batch_size, n_dim), dtype=np.float32)\n        z_id = np.empty((batch_size, 1), dtype=np.int32)\n        for batch in range(batch_size):\n            for zi in range((int)(n_dim/2)):\n                    a_sample, a_label = sample(n_labels)\n                    z[batch, zi*2:zi*2+2] = a_sample\n                    z_id[batch] = a_label\n        return z, z_id\n    else:\n        z = np.random.normal(mean, var, (batch_size, n_dim)).astype(np.float32)\n        return z\n\ndef gaussian_mixture(batch_size, n_dim=2, n_labels=10, x_var=0.5, y_var=0.1, label_indices=None):\n    if n_dim != 2:\n        raise Exception(""n_dim must be 2."")\n\n    def sample(x, y, label, n_labels):\n        shift = 1.4\n        r = 2.0 * np.pi / float(n_labels) * float(label)\n        new_x = x * cos(r) - y * sin(r)\n        new_y = x * sin(r) + y * cos(r)\n        new_x += shift * cos(r)\n        new_y += shift * sin(r)\n        return np.array([new_x, new_y]).reshape((2,))\n\n    x = np.random.normal(0, x_var, (batch_size, (int)(n_dim/2)))\n    y = np.random.normal(0, y_var, (batch_size, (int)(n_dim/2)))\n    z = np.empty((batch_size, n_dim), dtype=np.float32)\n    for batch in range(batch_size):\n        for zi in range((int)(n_dim/2)):\n            if label_indices is not None:\n                z[batch, zi*2:zi*2+2] = sample(x[batch, zi], y[batch, zi], label_indices[batch], n_labels)\n            else:\n                z[batch, zi*2:zi*2+2] = sample(x[batch, zi], y[batch, zi], np.random.randint(0, n_labels), n_labels)\n\n    return z\n\ndef swiss_roll(batch_size, n_dim=2, n_labels=10, label_indices=None):\n    if n_dim != 2:\n        raise Exception(""n_dim must be 2."")\n\n    def sample(label, n_labels):\n        uni = np.random.uniform(0.0, 1.0) / float(n_labels) + float(label) / float(n_labels)\n        r = sqrt(uni) * 3.0\n        rad = np.pi * 4.0 * sqrt(uni)\n        x = r * cos(rad)\n        y = r * sin(rad)\n        return np.array([x, y]).reshape((2,))\n\n    z = np.zeros((batch_size, n_dim), dtype=np.float32)\n    for batch in range(batch_size):\n        for zi in range((int)(n_dim/2)):\n            if label_indices is not None:\n                z[batch, zi*2:zi*2+2] = sample(label_indices[batch], n_labels)\n            else:\n                z[batch, zi*2:zi*2+2] = sample(np.random.randint(0, n_labels), n_labels)\n    return z'"
utils.py,1,"b'""""""\nMost codes from https://github.com/carpedm20/DCGAN-tensorflow\n""""""\nfrom __future__ import division\nimport math\nimport random\nimport pprint\nimport scipy.misc\nimport numpy as np\nfrom time import gmtime, strftime\nfrom six.moves import xrange\nimport matplotlib.pyplot as plt\nimport os, gzip\n\nimport tensorflow as tf\nimport tensorflow.contrib.slim as slim\n\ndef load_mnist(dataset_name):\n    data_dir = os.path.join(""./data"", dataset_name)\n\n    def extract_data(filename, num_data, head_size, data_size):\n        with gzip.open(filename) as bytestream:\n            bytestream.read(head_size)\n            buf = bytestream.read(data_size * num_data)\n            data = np.frombuffer(buf, dtype=np.uint8).astype(np.float)\n        return data\n\n    data = extract_data(data_dir + \'/train-images-idx3-ubyte.gz\', 60000, 16, 28 * 28)\n    trX = data.reshape((60000, 28, 28, 1))\n\n    data = extract_data(data_dir + \'/train-labels-idx1-ubyte.gz\', 60000, 8, 1)\n    trY = data.reshape((60000))\n\n    data = extract_data(data_dir + \'/t10k-images-idx3-ubyte.gz\', 10000, 16, 28 * 28)\n    teX = data.reshape((10000, 28, 28, 1))\n\n    data = extract_data(data_dir + \'/t10k-labels-idx1-ubyte.gz\', 10000, 8, 1)\n    teY = data.reshape((10000))\n\n    trY = np.asarray(trY)\n    teY = np.asarray(teY)\n\n    X = np.concatenate((trX, teX), axis=0)\n    y = np.concatenate((trY, teY), axis=0).astype(np.int)\n\n    seed = 547\n    np.random.seed(seed)\n    np.random.shuffle(X)\n    np.random.seed(seed)\n    np.random.shuffle(y)\n\n    y_vec = np.zeros((len(y), 10), dtype=np.float)\n    for i, label in enumerate(y):\n        y_vec[i, y[i]] = 1.0\n\n    return X / 255., y_vec\n\ndef check_folder(log_dir):\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    return log_dir\n\ndef show_all_variables():\n    model_vars = tf.trainable_variables()\n    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n\ndef get_image(image_path, input_height, input_width, resize_height=64, resize_width=64, crop=True, grayscale=False):\n    image = imread(image_path, grayscale)\n    return transform(image, input_height, input_width, resize_height, resize_width, crop)\n\ndef save_images(images, size, image_path):\n    return imsave(inverse_transform(images), size, image_path)\n\ndef imread(path, grayscale = False):\n    if (grayscale):\n        return scipy.misc.imread(path, flatten = True).astype(np.float)\n    else:\n        return scipy.misc.imread(path).astype(np.float)\n\ndef merge_images(images, size):\n    return inverse_transform(images)\n\ndef merge(images, size):\n    h, w = images.shape[1], images.shape[2]\n    if (images.shape[3] in (3,4)):\n        c = images.shape[3]\n        img = np.zeros((h * size[0], w * size[1], c))\n        for idx, image in enumerate(images):\n            i = idx % size[1]\n            j = idx // size[1]\n            img[j * h:j * h + h, i * w:i * w + w, :] = image\n        return img\n    elif images.shape[3]==1:\n        img = np.zeros((h * size[0], w * size[1]))\n        for idx, image in enumerate(images):\n            i = idx % size[1]\n            j = idx // size[1]\n            img[j * h:j * h + h, i * w:i * w + w] = image[:,:,0]\n        return img\n    else:\n        raise ValueError(\'in merge(images,size) images parameter \'\'must have dimensions: HxW or HxWx3 or HxWx4\')\n\ndef imsave(images, size, path):\n    image = np.squeeze(merge(images, size))\n    return scipy.misc.imsave(path, image)\n\ndef center_crop(x, crop_h, crop_w, resize_h=64, resize_w=64):\n    if crop_w is None:\n        crop_w = crop_h\n    h, w = x.shape[:2]\n    j = int(round((h - crop_h)/2.))\n    i = int(round((w - crop_w)/2.))\n    return scipy.misc.imresize(x[j:j+crop_h, i:i+crop_w], [resize_h, resize_w])\n\ndef transform(image, input_height, input_width, resize_height=64, resize_width=64, crop=True):\n    if crop:\n        cropped_image = center_crop(image, input_height, input_width, resize_height, resize_width)\n    else:\n        cropped_image = scipy.misc.imresize(image, [resize_height, resize_width])\n    return np.array(cropped_image)/127.5 - 1.\n\ndef inverse_transform(images):\n    return (images+1.)/2.\n\n"""""" Drawing Tools """"""\n# borrowed from https://github.com/ykwon0407/variational_autoencoder/blob/master/variational_bayes.ipynb\ndef save_scattered_image(z, id, z_range_x, z_range_y, name=\'scattered_image.jpg\'):\n    N = 10\n    plt.figure(figsize=(8, 6))\n    plt.scatter(z[:, 0], z[:, 1], c=np.argmax(id, 1), marker=\'o\', edgecolor=\'none\', cmap=discrete_cmap(N, \'jet\'))\n    plt.colorbar(ticks=range(N))\n    axes = plt.gca()\n    axes.set_xlim([-z_range_x, z_range_x])\n    axes.set_ylim([-z_range_y, z_range_y])\n    plt.grid(True)\n    plt.savefig(name)\n\n# borrowed from https://gist.github.com/jakevdp/91077b0cae40f8f8244a\ndef discrete_cmap(N, base_cmap=None):\n    """"""Create an N-bin discrete colormap from the specified input map""""""\n\n    # Note that if base_cmap is a string or None, you can simply do\n    #    return plt.cm.get_cmap(base_cmap, N)\n    # The following works for string, None, or a colormap instance:\n\n    base = plt.cm.get_cmap(base_cmap)\n    color_list = base(np.linspace(0, 1, N))\n    cmap_name = base.name + str(N)\n    return base.from_list(cmap_name, color_list, N)'"
