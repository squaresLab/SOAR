file_path,api_count,code
Titanic/show_confusion_matrix.py,0,"b'class show_confusion_matrix:\n    def show_confusion(C,class_labels=[\'0\',\'1\']):\n        """"""\n        C: ndarray, shape (2,2) as given by scikit-learn confusion_matrix function\n        class_labels: list of strings, default simply labels 0 and 1.\n\n        Draws confusion matrix with associated metrics.\n        """"""\n        import matplotlib.pyplot as plt\n        import numpy as np\n\n        assert C.shape == (2,2), ""Confusion matrix should be from binary classification only.""\n\n        # true negative, false positive, etc...\n        tn = C[0,0]; fp = C[0,1]; fn = C[1,0]; tp = C[1,1];\n\n        NP = fn+tp # Num positive examples\n        NN = tn+fp # Num negative examples\n        N  = NP+NN\n\n        fig = plt.figure(figsize=(8,8))\n        ax  = fig.add_subplot(111)\n        ax.imshow(C, interpolation=\'nearest\', cmap=plt.cm.gray)\n\n        # Draw the grid boxes\n        ax.set_xlim(-0.5,2.5)\n        ax.set_ylim(2.5,-0.5)\n        ax.plot([-0.5,2.5],[0.5,0.5], \'-k\', lw=2)\n        ax.plot([-0.5,2.5],[1.5,1.5], \'-k\', lw=2)\n        ax.plot([0.5,0.5],[-0.5,2.5], \'-k\', lw=2)\n        ax.plot([1.5,1.5],[-0.5,2.5], \'-k\', lw=2)\n\n        # Set xlabels\n        ax.set_xlabel(\'Predicted Label\', fontsize=16)\n        ax.set_xticks([0,1,2])\n        ax.set_xticklabels(class_labels + [\'\'])\n        ax.xaxis.set_label_position(\'top\')\n        ax.xaxis.tick_top()\n        # These coordinate might require some tinkering. Ditto for y, below.\n        ax.xaxis.set_label_coords(0.34,1.06)\n\n        # Set ylabels\n        ax.set_ylabel(\'True Label\', fontsize=16, rotation=90)\n        ax.set_yticklabels(class_labels + [\'\'],rotation=90)\n        ax.set_yticks([0,1,2])\n        ax.yaxis.set_label_coords(-0.09,0.65)\n\n\n        # Fill in initial metrics: tp, tn, etc...\n        ax.text(0,0,\n                \'True Neg: %d\\n(Num Neg: %d)\'%(tn,NN),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        ax.text(0,1,\n                \'False Neg: %d\'%fn,\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        ax.text(1,0,\n                \'False Pos: %d\'%fp,\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n\n        ax.text(1,1,\n                \'True Pos: %d\\n(Num Pos: %d)\'%(tp,NP),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        # Fill in secondary metrics: accuracy, true pos rate, etc...\n        ax.text(2,0,\n                \'False Pos Rate: %.2f\'%(fp / (fp+tn+0.)),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        ax.text(2,1,\n                \'True Pos Rate: %.2f\'%(tp / (tp+fn+0.)),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        ax.text(2,2,\n                \'Accuracy: %.2f\'%((tp+tn+0.)/N),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        ax.text(0,2,\n                \'Neg Pre Val: %.2f\'%(1-fn/(fn+tn+0.)),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n        ax.text(1,2,\n                \'Pos Pred Val: %.2f\'%(tp/(tp+fp+0.)),\n                va=\'center\',\n                ha=\'center\',\n                bbox=dict(fc=\'w\',boxstyle=\'round,pad=1\'))\n\n\n        plt.tight_layout()\n        plt.show()'"
